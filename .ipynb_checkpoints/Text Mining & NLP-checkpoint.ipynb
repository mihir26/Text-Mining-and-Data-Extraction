{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stopwords', 'stopwords.zip', 'wordnet', 'wordnet.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = \"\"\" Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers \"smart\". They work on their own without being encoded with commands. John McCarthy came up with the name \"Artificial Inteligencence\" in 1955.\n",
    "\n",
    "In general use, the term \"artificial intelligence\" means a programme which mimics human cognition. At least some of the things we associate with other minds, such as learning and problem solving can be done by computers, though not in the same way as we do. Andreas Kaplan and Michael Haenlein define AI as a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_tokens = word_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'AI',\n",
       " ')',\n",
       " 'is',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'of',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'or',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'to',\n",
       " 'think',\n",
       " 'and',\n",
       " 'learn',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " 'which',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'make',\n",
       " 'computers',\n",
       " '``',\n",
       " 'smart',\n",
       " \"''\",\n",
       " '.',\n",
       " 'They',\n",
       " 'work',\n",
       " 'on',\n",
       " 'their',\n",
       " 'own',\n",
       " 'without',\n",
       " 'being',\n",
       " 'encoded',\n",
       " 'with',\n",
       " 'commands',\n",
       " '.',\n",
       " 'John',\n",
       " 'McCarthy',\n",
       " 'came',\n",
       " 'up',\n",
       " 'with',\n",
       " 'the',\n",
       " 'name',\n",
       " '``',\n",
       " 'Artificial',\n",
       " 'Inteligencence',\n",
       " \"''\",\n",
       " 'in',\n",
       " '1955',\n",
       " '.',\n",
       " 'In',\n",
       " 'general',\n",
       " 'use',\n",
       " ',',\n",
       " 'the',\n",
       " 'term',\n",
       " '``',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " \"''\",\n",
       " 'means',\n",
       " 'a',\n",
       " 'programme',\n",
       " 'which',\n",
       " 'mimics',\n",
       " 'human',\n",
       " 'cognition',\n",
       " '.',\n",
       " 'At',\n",
       " 'least',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'things',\n",
       " 'we',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'other',\n",
       " 'minds',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'by',\n",
       " 'computers',\n",
       " ',',\n",
       " 'though',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'as',\n",
       " 'we',\n",
       " 'do',\n",
       " '.',\n",
       " 'Andreas',\n",
       " 'Kaplan',\n",
       " 'and',\n",
       " 'Michael',\n",
       " 'Haenlein',\n",
       " 'define',\n",
       " 'AI',\n",
       " 'as',\n",
       " 'a',\n",
       " 'system',\n",
       " '’',\n",
       " 's',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'correctly',\n",
       " 'interpret',\n",
       " 'external',\n",
       " 'data',\n",
       " ',',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'such',\n",
       " 'data',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'use',\n",
       " 'those',\n",
       " 'learnings',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'specific',\n",
       " 'goals',\n",
       " 'and',\n",
       " 'tasks',\n",
       " 'through',\n",
       " 'flexible',\n",
       " 'adaptation',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdlist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 7, 'to': 6, 'the': 5, 'a': 5, 'and': 5, ',': 5, 'artificial': 3, 'of': 3, '``': 3, \"''\": 3, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in AI_tokens:\n",
    "    fdlist[word.lower()]+=1\n",
    "fdlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 7),\n",
       " ('to', 6),\n",
       " ('the', 5),\n",
       " ('a', 5),\n",
       " ('and', 5),\n",
       " (',', 5),\n",
       " ('artificial', 3),\n",
       " ('of', 3),\n",
       " ('``', 3),\n",
       " (\"''\", 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdlist_top10 = fdlist.most_common(10)\n",
    "fdlist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "AI_blank = blankline_tokenize(AI)\n",
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence'),\n",
       " ('intelligence', '('),\n",
       " ('(', 'AI'),\n",
       " ('AI', ')'),\n",
       " (')', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'ability'),\n",
       " ('ability', 'of'),\n",
       " ('of', 'a'),\n",
       " ('a', 'computer'),\n",
       " ('computer', 'program'),\n",
       " ('program', 'or'),\n",
       " ('or', 'a'),\n",
       " ('a', 'machine'),\n",
       " ('machine', 'to'),\n",
       " ('to', 'think'),\n",
       " ('think', 'and'),\n",
       " ('and', 'learn'),\n",
       " ('learn', '.'),\n",
       " ('.', 'It'),\n",
       " ('It', 'is'),\n",
       " ('is', 'also'),\n",
       " ('also', 'a'),\n",
       " ('a', 'field'),\n",
       " ('field', 'of'),\n",
       " ('of', 'study'),\n",
       " ('study', 'which'),\n",
       " ('which', 'tries'),\n",
       " ('tries', 'to'),\n",
       " ('to', 'make'),\n",
       " ('make', 'computers'),\n",
       " ('computers', '``'),\n",
       " ('``', 'smart'),\n",
       " ('smart', \"''\"),\n",
       " (\"''\", '.'),\n",
       " ('.', 'They'),\n",
       " ('They', 'work'),\n",
       " ('work', 'on'),\n",
       " ('on', 'their'),\n",
       " ('their', 'own'),\n",
       " ('own', 'without'),\n",
       " ('without', 'being'),\n",
       " ('being', 'encoded'),\n",
       " ('encoded', 'with'),\n",
       " ('with', 'commands'),\n",
       " ('commands', '.'),\n",
       " ('.', 'John'),\n",
       " ('John', 'McCarthy'),\n",
       " ('McCarthy', 'came'),\n",
       " ('came', 'up'),\n",
       " ('up', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'name'),\n",
       " ('name', '``'),\n",
       " ('``', 'Artificial'),\n",
       " ('Artificial', 'Inteligencence'),\n",
       " ('Inteligencence', \"''\"),\n",
       " (\"''\", 'in'),\n",
       " ('in', '1955'),\n",
       " ('1955', '.'),\n",
       " ('.', 'In'),\n",
       " ('In', 'general'),\n",
       " ('general', 'use'),\n",
       " ('use', ','),\n",
       " (',', 'the'),\n",
       " ('the', 'term'),\n",
       " ('term', '``'),\n",
       " ('``', 'artificial'),\n",
       " ('artificial', 'intelligence'),\n",
       " ('intelligence', \"''\"),\n",
       " (\"''\", 'means'),\n",
       " ('means', 'a'),\n",
       " ('a', 'programme'),\n",
       " ('programme', 'which'),\n",
       " ('which', 'mimics'),\n",
       " ('mimics', 'human'),\n",
       " ('human', 'cognition'),\n",
       " ('cognition', '.'),\n",
       " ('.', 'At'),\n",
       " ('At', 'least'),\n",
       " ('least', 'some'),\n",
       " ('some', 'of'),\n",
       " ('of', 'the'),\n",
       " ('the', 'things'),\n",
       " ('things', 'we'),\n",
       " ('we', 'associate'),\n",
       " ('associate', 'with'),\n",
       " ('with', 'other'),\n",
       " ('other', 'minds'),\n",
       " ('minds', ','),\n",
       " (',', 'such'),\n",
       " ('such', 'as'),\n",
       " ('as', 'learning'),\n",
       " ('learning', 'and'),\n",
       " ('and', 'problem'),\n",
       " ('problem', 'solving'),\n",
       " ('solving', 'can'),\n",
       " ('can', 'be'),\n",
       " ('be', 'done'),\n",
       " ('done', 'by'),\n",
       " ('by', 'computers'),\n",
       " ('computers', ','),\n",
       " (',', 'though'),\n",
       " ('though', 'not'),\n",
       " ('not', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'same'),\n",
       " ('same', 'way'),\n",
       " ('way', 'as'),\n",
       " ('as', 'we'),\n",
       " ('we', 'do'),\n",
       " ('do', '.'),\n",
       " ('.', 'Andreas'),\n",
       " ('Andreas', 'Kaplan'),\n",
       " ('Kaplan', 'and'),\n",
       " ('and', 'Michael'),\n",
       " ('Michael', 'Haenlein'),\n",
       " ('Haenlein', 'define'),\n",
       " ('define', 'AI'),\n",
       " ('AI', 'as'),\n",
       " ('as', 'a'),\n",
       " ('a', 'system'),\n",
       " ('system', '’'),\n",
       " ('’', 's'),\n",
       " ('s', 'ability'),\n",
       " ('ability', 'to'),\n",
       " ('to', 'correctly'),\n",
       " ('correctly', 'interpret'),\n",
       " ('interpret', 'external'),\n",
       " ('external', 'data'),\n",
       " ('data', ','),\n",
       " (',', 'to'),\n",
       " ('to', 'learn'),\n",
       " ('learn', 'from'),\n",
       " ('from', 'such'),\n",
       " ('such', 'data'),\n",
       " ('data', ','),\n",
       " (',', 'and'),\n",
       " ('and', 'to'),\n",
       " ('to', 'use'),\n",
       " ('use', 'those'),\n",
       " ('those', 'learnings'),\n",
       " ('learnings', 'to'),\n",
       " ('to', 'achieve'),\n",
       " ('achieve', 'specific'),\n",
       " ('specific', 'goals'),\n",
       " ('goals', 'and'),\n",
       " ('and', 'tasks'),\n",
       " ('tasks', 'through'),\n",
       " ('through', 'flexible'),\n",
       " ('flexible', 'adaptation'),\n",
       " ('adaptation', '.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_bigrams = list(nltk.bigrams(AI_tokens))\n",
    "AI_bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence', '('),\n",
       " ('intelligence', '(', 'AI'),\n",
       " ('(', 'AI', ')'),\n",
       " ('AI', ')', 'is'),\n",
       " (')', 'is', 'the'),\n",
       " ('is', 'the', 'ability'),\n",
       " ('the', 'ability', 'of'),\n",
       " ('ability', 'of', 'a'),\n",
       " ('of', 'a', 'computer'),\n",
       " ('a', 'computer', 'program'),\n",
       " ('computer', 'program', 'or'),\n",
       " ('program', 'or', 'a'),\n",
       " ('or', 'a', 'machine'),\n",
       " ('a', 'machine', 'to'),\n",
       " ('machine', 'to', 'think'),\n",
       " ('to', 'think', 'and'),\n",
       " ('think', 'and', 'learn'),\n",
       " ('and', 'learn', '.'),\n",
       " ('learn', '.', 'It'),\n",
       " ('.', 'It', 'is'),\n",
       " ('It', 'is', 'also'),\n",
       " ('is', 'also', 'a'),\n",
       " ('also', 'a', 'field'),\n",
       " ('a', 'field', 'of'),\n",
       " ('field', 'of', 'study'),\n",
       " ('of', 'study', 'which'),\n",
       " ('study', 'which', 'tries'),\n",
       " ('which', 'tries', 'to'),\n",
       " ('tries', 'to', 'make'),\n",
       " ('to', 'make', 'computers'),\n",
       " ('make', 'computers', '``'),\n",
       " ('computers', '``', 'smart'),\n",
       " ('``', 'smart', \"''\"),\n",
       " ('smart', \"''\", '.'),\n",
       " (\"''\", '.', 'They'),\n",
       " ('.', 'They', 'work'),\n",
       " ('They', 'work', 'on'),\n",
       " ('work', 'on', 'their'),\n",
       " ('on', 'their', 'own'),\n",
       " ('their', 'own', 'without'),\n",
       " ('own', 'without', 'being'),\n",
       " ('without', 'being', 'encoded'),\n",
       " ('being', 'encoded', 'with'),\n",
       " ('encoded', 'with', 'commands'),\n",
       " ('with', 'commands', '.'),\n",
       " ('commands', '.', 'John'),\n",
       " ('.', 'John', 'McCarthy'),\n",
       " ('John', 'McCarthy', 'came'),\n",
       " ('McCarthy', 'came', 'up'),\n",
       " ('came', 'up', 'with'),\n",
       " ('up', 'with', 'the'),\n",
       " ('with', 'the', 'name'),\n",
       " ('the', 'name', '``'),\n",
       " ('name', '``', 'Artificial'),\n",
       " ('``', 'Artificial', 'Inteligencence'),\n",
       " ('Artificial', 'Inteligencence', \"''\"),\n",
       " ('Inteligencence', \"''\", 'in'),\n",
       " (\"''\", 'in', '1955'),\n",
       " ('in', '1955', '.'),\n",
       " ('1955', '.', 'In'),\n",
       " ('.', 'In', 'general'),\n",
       " ('In', 'general', 'use'),\n",
       " ('general', 'use', ','),\n",
       " ('use', ',', 'the'),\n",
       " (',', 'the', 'term'),\n",
       " ('the', 'term', '``'),\n",
       " ('term', '``', 'artificial'),\n",
       " ('``', 'artificial', 'intelligence'),\n",
       " ('artificial', 'intelligence', \"''\"),\n",
       " ('intelligence', \"''\", 'means'),\n",
       " (\"''\", 'means', 'a'),\n",
       " ('means', 'a', 'programme'),\n",
       " ('a', 'programme', 'which'),\n",
       " ('programme', 'which', 'mimics'),\n",
       " ('which', 'mimics', 'human'),\n",
       " ('mimics', 'human', 'cognition'),\n",
       " ('human', 'cognition', '.'),\n",
       " ('cognition', '.', 'At'),\n",
       " ('.', 'At', 'least'),\n",
       " ('At', 'least', 'some'),\n",
       " ('least', 'some', 'of'),\n",
       " ('some', 'of', 'the'),\n",
       " ('of', 'the', 'things'),\n",
       " ('the', 'things', 'we'),\n",
       " ('things', 'we', 'associate'),\n",
       " ('we', 'associate', 'with'),\n",
       " ('associate', 'with', 'other'),\n",
       " ('with', 'other', 'minds'),\n",
       " ('other', 'minds', ','),\n",
       " ('minds', ',', 'such'),\n",
       " (',', 'such', 'as'),\n",
       " ('such', 'as', 'learning'),\n",
       " ('as', 'learning', 'and'),\n",
       " ('learning', 'and', 'problem'),\n",
       " ('and', 'problem', 'solving'),\n",
       " ('problem', 'solving', 'can'),\n",
       " ('solving', 'can', 'be'),\n",
       " ('can', 'be', 'done'),\n",
       " ('be', 'done', 'by'),\n",
       " ('done', 'by', 'computers'),\n",
       " ('by', 'computers', ','),\n",
       " ('computers', ',', 'though'),\n",
       " (',', 'though', 'not'),\n",
       " ('though', 'not', 'in'),\n",
       " ('not', 'in', 'the'),\n",
       " ('in', 'the', 'same'),\n",
       " ('the', 'same', 'way'),\n",
       " ('same', 'way', 'as'),\n",
       " ('way', 'as', 'we'),\n",
       " ('as', 'we', 'do'),\n",
       " ('we', 'do', '.'),\n",
       " ('do', '.', 'Andreas'),\n",
       " ('.', 'Andreas', 'Kaplan'),\n",
       " ('Andreas', 'Kaplan', 'and'),\n",
       " ('Kaplan', 'and', 'Michael'),\n",
       " ('and', 'Michael', 'Haenlein'),\n",
       " ('Michael', 'Haenlein', 'define'),\n",
       " ('Haenlein', 'define', 'AI'),\n",
       " ('define', 'AI', 'as'),\n",
       " ('AI', 'as', 'a'),\n",
       " ('as', 'a', 'system'),\n",
       " ('a', 'system', '’'),\n",
       " ('system', '’', 's'),\n",
       " ('’', 's', 'ability'),\n",
       " ('s', 'ability', 'to'),\n",
       " ('ability', 'to', 'correctly'),\n",
       " ('to', 'correctly', 'interpret'),\n",
       " ('correctly', 'interpret', 'external'),\n",
       " ('interpret', 'external', 'data'),\n",
       " ('external', 'data', ','),\n",
       " ('data', ',', 'to'),\n",
       " (',', 'to', 'learn'),\n",
       " ('to', 'learn', 'from'),\n",
       " ('learn', 'from', 'such'),\n",
       " ('from', 'such', 'data'),\n",
       " ('such', 'data', ','),\n",
       " ('data', ',', 'and'),\n",
       " (',', 'and', 'to'),\n",
       " ('and', 'to', 'use'),\n",
       " ('to', 'use', 'those'),\n",
       " ('use', 'those', 'learnings'),\n",
       " ('those', 'learnings', 'to'),\n",
       " ('learnings', 'to', 'achieve'),\n",
       " ('to', 'achieve', 'specific'),\n",
       " ('achieve', 'specific', 'goals'),\n",
       " ('specific', 'goals', 'and'),\n",
       " ('goals', 'and', 'tasks'),\n",
       " ('and', 'tasks', 'through'),\n",
       " ('tasks', 'through', 'flexible'),\n",
       " ('through', 'flexible', 'adaptation'),\n",
       " ('flexible', 'adaptation', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_trigrams = list(nltk.trigrams(AI_tokens))\n",
    "AI_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'intelligence', '(', 'AI'),\n",
       " ('intelligence', '(', 'AI', ')'),\n",
       " ('(', 'AI', ')', 'is'),\n",
       " ('AI', ')', 'is', 'the'),\n",
       " (')', 'is', 'the', 'ability'),\n",
       " ('is', 'the', 'ability', 'of'),\n",
       " ('the', 'ability', 'of', 'a'),\n",
       " ('ability', 'of', 'a', 'computer'),\n",
       " ('of', 'a', 'computer', 'program'),\n",
       " ('a', 'computer', 'program', 'or'),\n",
       " ('computer', 'program', 'or', 'a'),\n",
       " ('program', 'or', 'a', 'machine'),\n",
       " ('or', 'a', 'machine', 'to'),\n",
       " ('a', 'machine', 'to', 'think'),\n",
       " ('machine', 'to', 'think', 'and'),\n",
       " ('to', 'think', 'and', 'learn'),\n",
       " ('think', 'and', 'learn', '.'),\n",
       " ('and', 'learn', '.', 'It'),\n",
       " ('learn', '.', 'It', 'is'),\n",
       " ('.', 'It', 'is', 'also'),\n",
       " ('It', 'is', 'also', 'a'),\n",
       " ('is', 'also', 'a', 'field'),\n",
       " ('also', 'a', 'field', 'of'),\n",
       " ('a', 'field', 'of', 'study'),\n",
       " ('field', 'of', 'study', 'which'),\n",
       " ('of', 'study', 'which', 'tries'),\n",
       " ('study', 'which', 'tries', 'to'),\n",
       " ('which', 'tries', 'to', 'make'),\n",
       " ('tries', 'to', 'make', 'computers'),\n",
       " ('to', 'make', 'computers', '``'),\n",
       " ('make', 'computers', '``', 'smart'),\n",
       " ('computers', '``', 'smart', \"''\"),\n",
       " ('``', 'smart', \"''\", '.'),\n",
       " ('smart', \"''\", '.', 'They'),\n",
       " (\"''\", '.', 'They', 'work'),\n",
       " ('.', 'They', 'work', 'on'),\n",
       " ('They', 'work', 'on', 'their'),\n",
       " ('work', 'on', 'their', 'own'),\n",
       " ('on', 'their', 'own', 'without'),\n",
       " ('their', 'own', 'without', 'being'),\n",
       " ('own', 'without', 'being', 'encoded'),\n",
       " ('without', 'being', 'encoded', 'with'),\n",
       " ('being', 'encoded', 'with', 'commands'),\n",
       " ('encoded', 'with', 'commands', '.'),\n",
       " ('with', 'commands', '.', 'John'),\n",
       " ('commands', '.', 'John', 'McCarthy'),\n",
       " ('.', 'John', 'McCarthy', 'came'),\n",
       " ('John', 'McCarthy', 'came', 'up'),\n",
       " ('McCarthy', 'came', 'up', 'with'),\n",
       " ('came', 'up', 'with', 'the'),\n",
       " ('up', 'with', 'the', 'name'),\n",
       " ('with', 'the', 'name', '``'),\n",
       " ('the', 'name', '``', 'Artificial'),\n",
       " ('name', '``', 'Artificial', 'Inteligencence'),\n",
       " ('``', 'Artificial', 'Inteligencence', \"''\"),\n",
       " ('Artificial', 'Inteligencence', \"''\", 'in'),\n",
       " ('Inteligencence', \"''\", 'in', '1955'),\n",
       " (\"''\", 'in', '1955', '.'),\n",
       " ('in', '1955', '.', 'In'),\n",
       " ('1955', '.', 'In', 'general'),\n",
       " ('.', 'In', 'general', 'use'),\n",
       " ('In', 'general', 'use', ','),\n",
       " ('general', 'use', ',', 'the'),\n",
       " ('use', ',', 'the', 'term'),\n",
       " (',', 'the', 'term', '``'),\n",
       " ('the', 'term', '``', 'artificial'),\n",
       " ('term', '``', 'artificial', 'intelligence'),\n",
       " ('``', 'artificial', 'intelligence', \"''\"),\n",
       " ('artificial', 'intelligence', \"''\", 'means'),\n",
       " ('intelligence', \"''\", 'means', 'a'),\n",
       " (\"''\", 'means', 'a', 'programme'),\n",
       " ('means', 'a', 'programme', 'which'),\n",
       " ('a', 'programme', 'which', 'mimics'),\n",
       " ('programme', 'which', 'mimics', 'human'),\n",
       " ('which', 'mimics', 'human', 'cognition'),\n",
       " ('mimics', 'human', 'cognition', '.'),\n",
       " ('human', 'cognition', '.', 'At'),\n",
       " ('cognition', '.', 'At', 'least'),\n",
       " ('.', 'At', 'least', 'some'),\n",
       " ('At', 'least', 'some', 'of'),\n",
       " ('least', 'some', 'of', 'the'),\n",
       " ('some', 'of', 'the', 'things'),\n",
       " ('of', 'the', 'things', 'we'),\n",
       " ('the', 'things', 'we', 'associate'),\n",
       " ('things', 'we', 'associate', 'with'),\n",
       " ('we', 'associate', 'with', 'other'),\n",
       " ('associate', 'with', 'other', 'minds'),\n",
       " ('with', 'other', 'minds', ','),\n",
       " ('other', 'minds', ',', 'such'),\n",
       " ('minds', ',', 'such', 'as'),\n",
       " (',', 'such', 'as', 'learning'),\n",
       " ('such', 'as', 'learning', 'and'),\n",
       " ('as', 'learning', 'and', 'problem'),\n",
       " ('learning', 'and', 'problem', 'solving'),\n",
       " ('and', 'problem', 'solving', 'can'),\n",
       " ('problem', 'solving', 'can', 'be'),\n",
       " ('solving', 'can', 'be', 'done'),\n",
       " ('can', 'be', 'done', 'by'),\n",
       " ('be', 'done', 'by', 'computers'),\n",
       " ('done', 'by', 'computers', ','),\n",
       " ('by', 'computers', ',', 'though'),\n",
       " ('computers', ',', 'though', 'not'),\n",
       " (',', 'though', 'not', 'in'),\n",
       " ('though', 'not', 'in', 'the'),\n",
       " ('not', 'in', 'the', 'same'),\n",
       " ('in', 'the', 'same', 'way'),\n",
       " ('the', 'same', 'way', 'as'),\n",
       " ('same', 'way', 'as', 'we'),\n",
       " ('way', 'as', 'we', 'do'),\n",
       " ('as', 'we', 'do', '.'),\n",
       " ('we', 'do', '.', 'Andreas'),\n",
       " ('do', '.', 'Andreas', 'Kaplan'),\n",
       " ('.', 'Andreas', 'Kaplan', 'and'),\n",
       " ('Andreas', 'Kaplan', 'and', 'Michael'),\n",
       " ('Kaplan', 'and', 'Michael', 'Haenlein'),\n",
       " ('and', 'Michael', 'Haenlein', 'define'),\n",
       " ('Michael', 'Haenlein', 'define', 'AI'),\n",
       " ('Haenlein', 'define', 'AI', 'as'),\n",
       " ('define', 'AI', 'as', 'a'),\n",
       " ('AI', 'as', 'a', 'system'),\n",
       " ('as', 'a', 'system', '’'),\n",
       " ('a', 'system', '’', 's'),\n",
       " ('system', '’', 's', 'ability'),\n",
       " ('’', 's', 'ability', 'to'),\n",
       " ('s', 'ability', 'to', 'correctly'),\n",
       " ('ability', 'to', 'correctly', 'interpret'),\n",
       " ('to', 'correctly', 'interpret', 'external'),\n",
       " ('correctly', 'interpret', 'external', 'data'),\n",
       " ('interpret', 'external', 'data', ','),\n",
       " ('external', 'data', ',', 'to'),\n",
       " ('data', ',', 'to', 'learn'),\n",
       " (',', 'to', 'learn', 'from'),\n",
       " ('to', 'learn', 'from', 'such'),\n",
       " ('learn', 'from', 'such', 'data'),\n",
       " ('from', 'such', 'data', ','),\n",
       " ('such', 'data', ',', 'and'),\n",
       " ('data', ',', 'and', 'to'),\n",
       " (',', 'and', 'to', 'use'),\n",
       " ('and', 'to', 'use', 'those'),\n",
       " ('to', 'use', 'those', 'learnings'),\n",
       " ('use', 'those', 'learnings', 'to'),\n",
       " ('those', 'learnings', 'to', 'achieve'),\n",
       " ('learnings', 'to', 'achieve', 'specific'),\n",
       " ('to', 'achieve', 'specific', 'goals'),\n",
       " ('achieve', 'specific', 'goals', 'and'),\n",
       " ('specific', 'goals', 'and', 'tasks'),\n",
       " ('goals', 'and', 'tasks', 'through'),\n",
       " ('and', 'tasks', 'through', 'flexible'),\n",
       " ('tasks', 'through', 'flexible', 'adaptation'),\n",
       " ('through', 'flexible', 'adaptation', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_ngrams = list(nltk.ngrams(AI_tokens,4))\n",
    "AI_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem_words = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_words.stem(\"having\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gave : gave\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = [\"give\",\"giving\",\"given\",\"gave\"]\n",
    "for words in words_to_stem:\n",
    "    print(words , \":\",stem_words.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : giv\n",
      "giving : giv\n",
      "given : giv\n",
      "gave : gav\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "x = LancasterStemmer()\n",
    "for words in words_to_stem:\n",
    "    print(words,\":\",x.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : give\n",
      "given : given\n",
      "gave : gave\n"
     ]
    }
   ],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "for words in words_to_stem:\n",
    "    print(words,\":\",sno.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_len = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mihir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give : give\n",
      "giving : giving\n",
      "given : given\n",
      "gave : gave\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words,\":\",word_len.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 7),\n",
       " ('to', 6),\n",
       " ('the', 5),\n",
       " ('a', 5),\n",
       " ('and', 5),\n",
       " (',', 5),\n",
       " ('artificial', 3),\n",
       " ('of', 3),\n",
       " ('``', 3),\n",
       " (\"''\", 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdlist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9``\\' \"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "for words in AI_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'the',\n",
       " 'ability',\n",
       " 'of',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'or',\n",
       " 'a',\n",
       " 'machine',\n",
       " 'to',\n",
       " 'think',\n",
       " 'and',\n",
       " 'learn',\n",
       " 'It',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'field',\n",
       " 'of',\n",
       " 'study',\n",
       " 'which',\n",
       " 'tries',\n",
       " 'to',\n",
       " 'make',\n",
       " 'computers',\n",
       " 'smart',\n",
       " 'They',\n",
       " 'work',\n",
       " 'on',\n",
       " 'their',\n",
       " 'own',\n",
       " 'without',\n",
       " 'being',\n",
       " 'encoded',\n",
       " 'with',\n",
       " 'commands',\n",
       " 'John',\n",
       " 'McCarthy',\n",
       " 'came',\n",
       " 'up',\n",
       " 'with',\n",
       " 'the',\n",
       " 'name',\n",
       " 'Artificial',\n",
       " 'Inteligencence',\n",
       " 'in',\n",
       " 'In',\n",
       " 'general',\n",
       " 'use',\n",
       " 'the',\n",
       " 'term',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'means',\n",
       " 'a',\n",
       " 'programme',\n",
       " 'which',\n",
       " 'mimics',\n",
       " 'human',\n",
       " 'cognition',\n",
       " 'At',\n",
       " 'least',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'things',\n",
       " 'we',\n",
       " 'associate',\n",
       " 'with',\n",
       " 'other',\n",
       " 'minds',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'can',\n",
       " 'be',\n",
       " 'done',\n",
       " 'by',\n",
       " 'computers',\n",
       " 'though',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'as',\n",
       " 'we',\n",
       " 'do',\n",
       " 'Andreas',\n",
       " 'Kaplan',\n",
       " 'and',\n",
       " 'Michael',\n",
       " 'Haenlein',\n",
       " 'define',\n",
       " 'AI',\n",
       " 'as',\n",
       " 'a',\n",
       " 'system',\n",
       " '’',\n",
       " 's',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'correctly',\n",
       " 'interpret',\n",
       " 'external',\n",
       " 'data',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'such',\n",
       " 'data',\n",
       " 'and',\n",
       " 'to',\n",
       " 'use',\n",
       " 'those',\n",
       " 'learnings',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'specific',\n",
       " 'goals',\n",
       " 'and',\n",
       " 'tasks',\n",
       " 'through',\n",
       " 'flexible',\n",
       " 'adaptation']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
